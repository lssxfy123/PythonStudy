{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4904, -0.6312],\n",
       "        [-1.9918, -0.8161]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 2)  # 正态分布的随机数\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4904, -0.6312],\n",
       "        [-1.9918, -0.8161]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 使用torch.autograd中的Variable封装张量，并且指明需要梯度\n",
    "x = Variable(x, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2405, 0.3984],\n",
       "        [3.9671, 0.6660]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grad_fn看出执行了Pow运算\n",
    "y = x ** 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x的梯度为空\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标量才能隐式创建梯度\n",
    "# y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3180, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y.mean()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要计算梯度，你需要对 Variable（例如 `z`）运行 `.backward` 方法。这样会计算 `z` 相对于 `x` 的梯度\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2452, -0.3156],\n",
       "        [-0.9959, -0.4081]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x.grad确实是x / 2\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 下载数据\n",
    "# transform将图片转换为神经网络需要的数据\n",
    "# 图像每个通道元素-0.5，然后再除以0.5，从0-1转变为-1到1\n",
    "transform= transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "## 训练集\n",
    "train_set = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "## 测试集\n",
    "test_set = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 神经网络模型\n",
    "input_size = 784\n",
    "hidden_size = [200, 50]\n",
    "output_size = 10\n",
    "model = nn.Sequential(OrderedDict([('fc1', nn.Linear(input_size, hidden_size[0])),\n",
    "                                  ('relu1', nn.ReLU()),\n",
    "                                  ('fc2', nn.Linear(hidden_size[0], hidden_size[1])),\n",
    "                                  ('relu2', nn.ReLU()),\n",
    "                                  ('fc3', nn.Linear(hidden_size[1], output_size)),\n",
    "                                  ('softmax', nn.Softmax(dim=1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "## 优化器（SGD）\n",
    "## 优化所有参数，学习率设置为0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们只考虑${\\color{red}{一个学习步}}$，然后再循环访问所有数据。PyTorch 的一般流程是：\n",
    "\n",
    "* 在网络中进行前向传递以获得 logits\n",
    "* 使用 logits 计算损失\n",
    "* 通过 `loss.backward()` 对网络进行反向传递以计算梯度\n",
    "* 用优化器执行一步以更新权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "## 把所有梯度都清零\n",
    "## 每次反向传播都会计算梯度，如果不清零，则会累积\n",
    "optimizer.zero_grad()\n",
    "\n",
    "## 数据包装\n",
    "inputs = Variable(images)\n",
    "targets = Variable(labels)\n",
    "\n",
    "## 前向反馈\n",
    "outputs = model.forward(inputs)\n",
    "loss = criterion(outputs, targets)  ## 计算损失\n",
    "\n",
    "## 反向传播\n",
    "loss.backward()\n",
    "\n",
    "## 使用优化器更新权重\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实际训练\n",
    "\n",
    "现在，我们将此算法用于循环中，以便访问所有图像。很简单，我们将循环访问数据集的小批次数据，在网络中传递数据以计算损失，获得梯度，然后运行优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 创建Network类\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 输入层，784(28x28)个输入结点, 200个输出结点\n",
    "        self.fc1 = nn.Linear(784, 200)\n",
    "        \n",
    "        # 隐藏层1，128个结点\n",
    "        self.fc2 = nn.Linear(200, 50)\n",
    "        \n",
    "        # 隐藏层2，50个结点，10个输出结点\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "\n",
    "    # 前向反馈\n",
    "    # 多个线性模型组合\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)  ## 使用ReLU作为激活函数\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)  ## 使用ReLU作为激活函数\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        \n",
    "        # 输出层的激活函数为softmax\n",
    "        return F.softmax(logits, dim=1)\n",
    "\n",
    "net = Network()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1 Loss: 1.1248 Test accuracy: 0.7035\n",
      "Epoch: 1/1 Loss: 0.7310 Test accuracy: 0.7967\n",
      "Epoch: 1/1 Loss: 0.6384 Test accuracy: 0.7894\n",
      "Epoch: 1/1 Loss: 0.6110 Test accuracy: 0.8500\n",
      "Epoch: 1/1 Loss: 0.5012 Test accuracy: 0.8694\n",
      "Epoch: 1/1 Loss: 0.4228 Test accuracy: 0.8526\n",
      "Epoch: 1/1 Loss: 0.5081 Test accuracy: 0.8671\n",
      "Epoch: 1/1 Loss: 0.3865 Test accuracy: 0.8869\n",
      "Epoch: 1/1 Loss: 0.3917 Test accuracy: 0.8882\n",
      "Epoch: 1/1 Loss: 0.3978 Test accuracy: 0.8830\n",
      "Epoch: 1/1 Loss: 0.3578 Test accuracy: 0.8953\n",
      "Epoch: 1/1 Loss: 0.3143 Test accuracy: 0.9052\n",
      "Epoch: 1/1 Loss: 0.3381 Test accuracy: 0.8992\n",
      "Epoch: 1/1 Loss: 0.3934 Test accuracy: 0.9036\n",
      "Epoch: 1/1 Loss: 0.3581 Test accuracy: 0.9011\n",
      "Epoch: 1/1 Loss: 0.4082 Test accuracy: 0.9017\n",
      "Epoch: 1/1 Loss: 0.3407 Test accuracy: 0.9136\n",
      "Epoch: 1/1 Loss: 0.3620 Test accuracy: 0.9110\n",
      "Epoch: 1/1 Loss: 0.3176 Test accuracy: 0.9074\n",
      "Epoch: 1/1 Loss: 0.3342 Test accuracy: 0.9185\n",
      "Epoch: 1/1 Loss: 0.2703 Test accuracy: 0.9220\n",
      "Epoch: 1/1 Loss: 0.2852 Test accuracy: 0.9096\n",
      "Epoch: 1/1 Loss: 0.3310 Test accuracy: 0.9234\n",
      "Epoch: 1/1 Loss: 0.2914 Test accuracy: 0.9212\n",
      "Epoch: 1/1 Loss: 0.2592 Test accuracy: 0.9113\n",
      "Epoch: 1/1 Loss: 0.3415 Test accuracy: 0.9213\n",
      "Epoch: 1/1 Loss: 0.2859 Test accuracy: 0.9096\n",
      "Epoch: 1/1 Loss: 0.2894 Test accuracy: 0.9222\n",
      "Epoch: 1/1 Loss: 0.2898 Test accuracy: 0.9282\n",
      "Epoch: 1/1 Loss: 0.2782 Test accuracy: 0.9284\n",
      "Epoch: 1/1 Loss: 0.2592 Test accuracy: 0.9320\n",
      "Epoch: 1/1 Loss: 0.2707 Test accuracy: 0.9304\n",
      "Epoch: 1/1 Loss: 0.2405 Test accuracy: 0.9312\n",
      "Epoch: 1/1 Loss: 0.2406 Test accuracy: 0.9273\n",
      "Epoch: 1/1 Loss: 0.2551 Test accuracy: 0.9143\n",
      "Epoch: 1/1 Loss: 0.2629 Test accuracy: 0.9235\n",
      "Epoch: 1/1 Loss: 0.2341 Test accuracy: 0.9295\n",
      "Epoch: 1/1 Loss: 0.2457 Test accuracy: 0.9241\n",
      "Epoch: 1/1 Loss: 0.2501 Test accuracy: 0.9319\n",
      "Epoch: 1/1 Loss: 0.2498 Test accuracy: 0.9243\n",
      "Epoch: 1/1 Loss: 0.2707 Test accuracy: 0.9280\n",
      "Epoch: 1/1 Loss: 0.2378 Test accuracy: 0.9374\n",
      "Epoch: 1/1 Loss: 0.2296 Test accuracy: 0.9376\n",
      "Epoch: 1/1 Loss: 0.2206 Test accuracy: 0.9323\n",
      "Epoch: 1/1 Loss: 0.2019 Test accuracy: 0.9397\n",
      "Epoch: 1/1 Loss: 0.2429 Test accuracy: 0.9376\n"
     ]
    }
   ],
   "source": [
    "## 训练周期，每个周期使用所有数据进行前向反馈和反向传播\n",
    "epochs = 1  # 大于1，会出现过拟合，可以看到loss开始上升\n",
    "print_every = 20\n",
    "steps = 0\n",
    "\n",
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in iter(train_loader):\n",
    "        steps += 1\n",
    "        \n",
    "        images.resize_(images.shape[0], input_size)\n",
    "        optimizer.zero_grad()\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(labels)\n",
    "        \n",
    "        outputs = net.forward(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            accuracy = 0\n",
    "            for ii, (images, labels) in enumerate(test_loader):\n",
    "                \n",
    "                images = images.resize_(images.size()[0], 784)\n",
    "                inputs = Variable(images)\n",
    "                \n",
    "                predicted = net.predict(inputs).data\n",
    "                equality = (labels == predicted.max(1)[1])\n",
    "                accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "            \n",
    "            print(\"Epoch: {}/{}\".format(i+1, epochs),\n",
    "                  \"Loss: {:.4f}\".format(running_loss/print_every),\n",
    "                  \"Test accuracy: {:.4f}\".format(accuracy/(ii+1)))\n",
    "            \n",
    "            running_loss = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = images[1]  ## 修改索引值，可以看到不同的数字图像对应的概率\n",
    "ps = net.predict(Variable(img.resize_(1, 784)))\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
