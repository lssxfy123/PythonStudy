{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自己构建的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Lambda\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input as resnet50_pre\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as inceptionV3_pre\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input as xception_pre\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile  \n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, Input, Activation\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import cv2                \n",
    "import matplotlib.pyplot as plt    \n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline \n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import h5py\n",
    "import common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对图片进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, valid_generator = common.data_generator((224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', input_shape=(224, 224, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8/8 [==============================] - ETA: 34s - loss: 0.8084 - acc: 0.35 - ETA: 24s - loss: 1.8969 - acc: 0.42 - ETA: 18s - loss: 1.5879 - acc: 0.40 - ETA: 14s - loss: 1.4424 - acc: 0.38 - ETA: 10s - loss: 1.2731 - acc: 0.45 - ETA: 6s - loss: 1.1851 - acc: 0.4667 - ETA: 3s - loss: 1.1255 - acc: 0.471 - 27s 3s/step - loss: 1.0849 - acc: 0.4500 - val_loss: 0.6928 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69275, saving model to user-defined.hdf5\n",
      "Epoch 2/5\n",
      "8/8 [==============================] - ETA: 19s - loss: 0.6854 - acc: 0.55 - ETA: 16s - loss: 0.6903 - acc: 0.52 - ETA: 13s - loss: 0.6908 - acc: 0.50 - ETA: 10s - loss: 0.6895 - acc: 0.51 - ETA: 8s - loss: 0.6888 - acc: 0.5600 - ETA: 5s - loss: 0.6893 - acc: 0.566 - ETA: 2s - loss: 0.6900 - acc: 0.550 - 23s 3s/step - loss: 0.6901 - acc: 0.5563 - val_loss: 0.6929 - val_acc: 0.5750\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.69275\n",
      "Epoch 3/5\n",
      "8/8 [==============================] - ETA: 19s - loss: 0.6952 - acc: 0.45 - ETA: 16s - loss: 0.6942 - acc: 0.47 - ETA: 13s - loss: 0.6939 - acc: 0.45 - ETA: 10s - loss: 0.6936 - acc: 0.46 - ETA: 8s - loss: 0.6935 - acc: 0.4900 - ETA: 5s - loss: 0.6935 - acc: 0.491 - ETA: 2s - loss: 0.6935 - acc: 0.492 - 29s 4s/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6934 - val_acc: 0.4750\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69275\n",
      "Epoch 4/5\n",
      "8/8 [==============================] - ETA: 19s - loss: 0.6939 - acc: 0.40 - ETA: 26s - loss: 0.6930 - acc: 0.47 - ETA: 19s - loss: 0.6922 - acc: 0.53 - ETA: 14s - loss: 0.6923 - acc: 0.53 - ETA: 10s - loss: 0.6924 - acc: 0.55 - ETA: 7s - loss: 0.6922 - acc: 0.5500 - ETA: 3s - loss: 0.6922 - acc: 0.564 - 31s 4s/step - loss: 0.6923 - acc: 0.5563 - val_loss: 0.6934 - val_acc: 0.4250\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.69275\n",
      "Epoch 5/5\n",
      "8/8 [==============================] - ETA: 57s - loss: 0.6910 - acc: 0.45 - ETA: 32s - loss: 0.6918 - acc: 0.47 - ETA: 22s - loss: 0.6908 - acc: 0.53 - ETA: 21s - loss: 0.6900 - acc: 0.55 - ETA: 14s - loss: 0.6904 - acc: 0.54 - ETA: 9s - loss: 0.6939 - acc: 0.5083 - ETA: 4s - loss: 0.6930 - acc: 0.514 - 38s 5s/step - loss: 0.6938 - acc: 0.5062 - val_loss: 0.6911 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.69275 to 0.69107, saving model to user-defined.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xcc92c2d710>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='user-defined.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=train_generator.samples // common.batch_size, \n",
    "                    epochs=5, validation_data=valid_generator, validation_steps=valid_generator.samples // common.batch_size, \n",
    "                    callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('user-defined.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 253.00it/s]\n"
     ]
    }
   ],
   "source": [
    "## 预测\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    return files\n",
    "\n",
    "test_tensors = common.paths_to_tensor(load_dataset(common.test_path), (224, 224)).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
