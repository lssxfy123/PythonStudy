{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自己构建的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Lambda\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input as resnet50_pre\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as inceptionV3_pre\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input as xception_pre\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile  \n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, Input, Activation\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import cv2                \n",
    "import matplotlib.pyplot as plt    \n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline \n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对图片进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = 'dogs-vs-cats/train1/'\n",
    "test_path = 'dogs-vs-cats/test1/'\n",
    "valid_path = 'dogs-vs-cats/valid1/'\n",
    "\n",
    "if not os.path.exists(valid_path):\n",
    "    os.mkdir(valid_path)\n",
    "\n",
    "train_dog_path = train_path + 'dog/'\n",
    "train_cat_path = train_path + 'cat/'\n",
    "\n",
    "valid_dog_path = valid_path + 'dog/'\n",
    "valid_cat_path = valid_path + 'cat/'\n",
    "\n",
    "\n",
    "def move_data(names, path1, path2):\n",
    "    if not os.path.exists(path1):\n",
    "        os.mkdir(path1)\n",
    "        os.mkdir(path2)\n",
    "        \n",
    "    valid_names = random.sample(names, int(len(names) * 0.2))\n",
    "    train_names = [name for name in names if name not in valid_names]\n",
    "    [shutil.move(train_path + name, path1 + name) for name in train_names]\n",
    "    [shutil.move(train_path + name, path2 + name) for name in valid_names]\n",
    "\n",
    "if not os.path.exists(train_dog_path):\n",
    "    names= os.listdir(train_path)\n",
    "    cat_names = [name for name in names if name.startswith('cat')]\n",
    "    dog_names = [name for name in names if name.startswith('dog')]\n",
    "    move_data(cat_names, train_cat_path, valid_cat_path)\n",
    "    move_data(dog_names, train_dog_path, valid_dog_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, valid_generator = data_generator((224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', input_shape=(224, 224, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - ETA: 25s - loss: 0.6617 - acc: 0.56 - ETA: 16s - loss: 4.3164 - acc: 0.53 - ETA: 12s - loss: 6.1990 - acc: 0.47 - ETA: 9s - loss: 6.3166 - acc: 0.4219 - ETA: 7s - loss: 6.7618 - acc: 0.425 - ETA: 5s - loss: 6.2119 - acc: 0.437 - ETA: 4s - loss: 5.4438 - acc: 0.437 - ETA: 2s - loss: 4.8520 - acc: 0.445 - ETA: 1s - loss: 4.3953 - acc: 0.451 - 14s 1s/step - loss: 4.0233 - acc: 0.4562 - val_loss: 0.6923 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69227, saving model to user-defined.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bb08051390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='user-defined.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=train_generator.samples // batch_size, \n",
    "                    epochs=1, validation_data=valid_generator, validation_steps=valid_generator.samples // batch_size, \n",
    "                    callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('user-defined.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 100/100 [00:00<00:00, 352.37it/s]\n"
     ]
    }
   ],
   "source": [
    "## 预测\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    return files\n",
    "\n",
    "test_tensors = paths_to_tensor(load_dataset('dogs-vs-cats/test1/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -63.939003 ,  -39.779    ,   11.32     ],\n",
       "        [ -55.939003 ,  -31.779    ,   11.32     ],\n",
       "        [ -42.939003 ,  -17.779    ,    7.3199997],\n",
       "        ...,\n",
       "        [ -51.939003 ,  -75.779    , -102.68     ],\n",
       "        [ -46.939003 ,  -73.779    , -102.68     ],\n",
       "        [ -47.939003 ,  -74.779    , -103.68     ]],\n",
       "\n",
       "       [[ -54.939003 ,  -31.779    ,   15.32     ],\n",
       "        [ -54.939003 ,  -31.779    ,    7.3199997],\n",
       "        [ -43.939003 ,  -22.779    ,   -0.6800003],\n",
       "        ...,\n",
       "        [ -50.939003 ,  -74.779    , -101.68     ],\n",
       "        [ -46.939003 ,  -73.779    , -102.68     ],\n",
       "        [ -46.939003 ,  -73.779    , -102.68     ]],\n",
       "\n",
       "       [[ -56.939003 ,  -35.779    ,   -6.6800003],\n",
       "        [ -36.939003 ,  -19.779    ,    2.3199997],\n",
       "        [ -20.939003 ,  -15.778999 ,   -5.6800003],\n",
       "        ...,\n",
       "        [ -50.939003 ,  -74.779    , -101.68     ],\n",
       "        [ -45.939003 ,  -72.779    , -101.68     ],\n",
       "        [ -46.939003 ,  -73.779    , -102.68     ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ -64.939    ,  -93.779    , -116.68     ],\n",
       "        [ -64.939    ,  -93.779    , -116.68     ],\n",
       "        [ -64.939    ,  -93.779    , -116.68     ],\n",
       "        ...,\n",
       "        [ -20.939003 ,  -15.778999 ,   -5.6800003],\n",
       "        [ -21.939003 ,  -16.779    ,   -6.6800003],\n",
       "        [ -23.939003 ,  -18.779    ,   -8.68     ]],\n",
       "\n",
       "       [[ -65.939    ,  -94.779    , -117.68     ],\n",
       "        [ -65.939    ,  -94.779    , -117.68     ],\n",
       "        [ -65.939    ,  -94.779    , -117.68     ],\n",
       "        ...,\n",
       "        [ -24.939003 ,  -19.779    ,   -9.68     ],\n",
       "        [ -26.939003 ,  -21.779    ,  -11.68     ],\n",
       "        [ -28.939003 ,  -23.779    ,  -13.68     ]],\n",
       "\n",
       "       [[ -65.939    ,  -94.779    , -117.68     ],\n",
       "        [ -65.939    ,  -94.779    , -117.68     ],\n",
       "        [ -65.939    ,  -94.779    , -117.68     ],\n",
       "        ...,\n",
       "        [ -26.939003 ,  -21.779    ,  -11.68     ],\n",
       "        [ -28.939003 ,  -23.779    ,  -13.68     ],\n",
       "        [ -29.939003 ,  -24.779    ,  -14.68     ]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50_pre(test_tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
