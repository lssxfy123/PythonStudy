{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自己构建的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Lambda\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input as resnet50_pre\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as inceptionV3_pre\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input as xception_pre\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input as vgg16_pre\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as vgg19_pre\n",
    "from keras.preprocessing import image   \n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile  \n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, Input, Activation\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import cv2                \n",
    "import matplotlib.pyplot as plt    \n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline \n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import h5py\n",
    "import common\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对图片进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.divide_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_and_features = {}\n",
    "models_and_test_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_extract_features():\n",
    "    \n",
    "    # VGG16\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "    features_name = common.extract_features(base_model, (224, 224), vgg16_pre)\n",
    "    models_and_features['vgg16'] = features_name\n",
    "    \n",
    "    # VGG19\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, pooling='avg')\n",
    "    features_name = common.extract_features(base_model, (224, 224), vgg19_pre)\n",
    "    models_and_features['vgg19'] = features_name\n",
    "    \n",
    "    # ResNet50\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "    features_name = common.extract_features(base_model, (224, 224), resnet50_pre)\n",
    "    models_and_features['resnet50'] = features_name\n",
    "    \n",
    "    # InceptionV3\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "    features_name = common.extract_features(base_model, (299, 299), inceptionV3_pre)\n",
    "    models_and_features['inceptionV3'] = features_name\n",
    "    \n",
    "    # Xception\n",
    "    base_model = Xception(weights='imagenet', include_top=False, pooling='avg')\n",
    "    features_name = common.extract_features(base_model, (299, 299), xception_pre)\n",
    "    models_and_features['xception'] = features_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_extract_test_features():\n",
    "    \n",
    "    # VGG16\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "    features_name = common.extract_test_features(base_model, (224, 224), vgg16_pre)\n",
    "    models_and_test_features['vgg16'] = features_name\n",
    "    \n",
    "    # VGG19\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, pooling='avg')\n",
    "    features_name = common.extract_test_features(base_model, (224, 224), vgg19_pre)\n",
    "    models_and_test_features['vgg19'] = features_name\n",
    "    \n",
    "    # ResNet50\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "    features_name = common.extract_test_features(base_model, (224, 224), resnet50_pre)\n",
    "    models_and_test_features['resnet50'] = features_name\n",
    "    \n",
    "    # InceptionV3\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "    features_name = common.extract_test_features(base_model, (299, 299), inceptionV3_pre)\n",
    "    models_and_test_features['inceptionV3'] = features_name\n",
    "    \n",
    "    # Xception\n",
    "    base_model = Xception(weights='imagenet', include_top=False, pooling='avg')\n",
    "    features_name = common.extract_test_features(base_model, (299, 299), xception_pre)\n",
    "    models_and_test_features['xception'] = features_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19988 images belonging to 2 classes.\n",
      "Found 4995 images belonging to 2 classes.\n",
      "999/999 [==============================] - 162s 162ms/step\n",
      "249/249 [==============================] - 40s 160ms/step\n",
      "Found 19988 images belonging to 2 classes.\n",
      "Found 4995 images belonging to 2 classes.\n",
      "999/999 [==============================] - 192s 193ms/step\n",
      "249/249 [==============================] - 48s 193ms/step\n",
      "Found 19988 images belonging to 2 classes.\n",
      "Found 4995 images belonging to 2 classes.\n",
      "999/999 [==============================] - 170s 170ms/step\n",
      "249/249 [==============================] - 42s 170ms/step\n",
      "Found 19988 images belonging to 2 classes.\n",
      "Found 4995 images belonging to 2 classes.\n",
      "999/999 [==============================] - 204s 204ms/step\n",
      "249/249 [==============================] - 51s 204ms/step\n",
      "Found 19988 images belonging to 2 classes.\n",
      "Found 4995 images belonging to 2 classes.\n",
      "999/999 [==============================] - 338s 338ms/step\n",
      "249/249 [==============================] - 84s 337ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n",
      "625/625 [==============================] - 102s 163ms/step\n",
      "Found 12500 images belonging to 1 classes.\n",
      "625/625 [==============================] - 122s 195ms/step\n",
      "Found 12500 images belonging to 1 classes.\n",
      "625/625 [==============================] - 107s 172ms/step\n",
      "Found 12500 images belonging to 1 classes.\n",
      "625/625 [==============================] - 129s 207ms/step\n",
      "Found 12500 images belonging to 1 classes.\n",
      "625/625 [==============================] - 213s 341ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_extract_test_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(models_and_features) == 0:\n",
    "    models_and_features['vgg16'] = 'vgg16_features.npz'\n",
    "    models_and_features['vgg19'] = 'vgg19_features.npz'\n",
    "    models_and_features['resnet50'] = 'resnet50_features.npz'\n",
    "    models_and_features['inceptionV3'] = 'inception_v3_features.npz'\n",
    "    models_and_features['xception'] = 'xception_features.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(models_and_test_features) == 0:\n",
    "    models_and_test_features['vgg16'] = 'test_vgg16_features.npz'\n",
    "    models_and_test_features['vgg19'] = 'test_vgg19_features.npz'\n",
    "    models_and_test_features['resnet50'] = 'test_resnet50_features.npz'\n",
    "    models_and_test_features['inceptionV3'] = 'test_inception_v3_features.npz'\n",
    "    models_and_test_features['xception'] = 'test_xception_features.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_train(key, dropout, optimizer, file_header):\n",
    "    features = np.load(models_and_features[key])\n",
    "    features_test = np.load(models_and_test_features[key])\n",
    "    train_features = features['train']\n",
    "    train_labels = features['train_label'][:len(train_features)]\n",
    "    valid_features = features['valid']\n",
    "    valid_labels = features['valid_label'][:len(valid_features)]\n",
    "    test_features = features_test['test']\n",
    "    test_filenames = features_test['test_filename']\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(2048, input_shape=(train_features.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='{0}.hdf5'.format(file_header), verbose=1, save_best_only=True)\n",
    "    train_result = model.fit(train_features, train_labels, epochs=20, batch_size=common.batch_size,\n",
    "          validation_data=(valid_features, valid_labels), verbose=1, callbacks=[checkpointer])\n",
    "    \n",
    "    with open('{0}_history.pkl'.format(file_header), 'wb') as f:\n",
    "        pickle.dump(train_result.history, f)\n",
    "    model.load_weights('{0}.hdf5'.format(file_header))\n",
    "    prediction = model.predict(test_features, batch_size=common.batch_size)\n",
    "    prediction = prediction[:, 0].clip(0.01, 0.99)\n",
    "    test_fileindex = np.array([os.path.splitext(os.path.split(filename)[1])[0] for filename in test_filenames])\n",
    "    data = np.stack([test_fileindex, prediction], axis=1)\n",
    "    tmp = pd.DataFrame(data, columns=['id', 'label'])\n",
    "    tmp['id'] = tmp['id'].apply(pd.to_numeric)\n",
    "    submit_frame = pd.read_csv('dogs-vs-cats/sample_submission.csv')\n",
    "    result = pd.merge(submit_frame, tmp, on=\"id\", how='left')\n",
    "    result = result.rename(index=str, columns={\"label_y\": \"label\"})\n",
    "    result.dropna(axis=0, subset=['label'], inplace=True)\n",
    "    result[['id','label']].to_csv('{0}_predict.csv'.format(file_header),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('vgg16', 0.3, Adam(lr=0.001), 'vgg16_Adam_0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('vgg16', 0.5, Adam(lr=0.001), 'vgg16_Adam_0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('vgg16', 0.7, Adam(lr=0.001), 'vgg16_Adam_0.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('vgg16', 0.3, SGD(lr=0.001), 'vgg16_SGD_0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('vgg16', 0.5, SGD(lr=0.001), 'vgg16_SGD_0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('vgg16', 0.7, SGD(lr=0.001), 'vgg16_SGD_0.7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('vgg19', 0.3, Adam(lr=0.001), 'vgg19_Adam_0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('vgg19', 0.5, Adam(lr=0.001), 'vgg19_Adam_0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('vgg19', 0.7, Adam(lr=0.001), 'vgg19_Adam_0.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('vgg19', 0.3, SGD(lr=0.001), 'vgg19_SGD_0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('vgg19', 0.5, SGD(lr=0.001), 'vgg19_SGD_0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('vgg19', 0.7, SGD(lr=0.001), 'vgg19_SGD_0.7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('resnet50', 0.3, Adam(lr=0.001), 'resnet50_Adam_0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('resnet50', 0.5, Adam(lr=0.001), 'resnet50_Adam_0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('resnet50', 0.7, Adam(lr=0.001), 'resnet50_Adam_0.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('resnet50', 0.3, SGD(lr=0.001), 'resnet50_SGD_0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('resnet50', 0.5, SGD(lr=0.001), 'resnet50_SGD_0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('resnet50', 0.7, SGD(lr=0.001), 'resnet50_SGD_0.7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('inceptionV3', 0.3, Adam(lr=0.001), 'inceptionV3_Adam_0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('inceptionV3', 0.5, Adam(lr=0.001), 'inceptionV3_Adam_0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('inceptionV3', 0.7, Adam(lr=0.001), 'inceptionV3_Adam_0.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('inceptionV3', 0.3, SGD(lr=0.001), 'inceptionV3_SGD_0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('inceptionV3', 0.5, SGD(lr=0.001), 'inceptionV3_SGD_0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('inceptionV3', 0.7, SGD(lr=0.001), 'inceptionV3_SGD_0.7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('xception', 0.3, Adam(lr=0.001), 'xception_Adam_0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_train('xception', 0.5, Adam(lr=0.001), 'xception_Adam_0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('xception', 0.7, Adam(lr=0.001), 'xception_Adam_0.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('xception', 0.3, SGD(lr=0.001), 'xception_SGD_0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('xception', 0.5, SGD(lr=0.001), 'xception_SGD_0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train('xception', 0.7, SGD(lr=0.001), 'xception_SGD_0.7')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
