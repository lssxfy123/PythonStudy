{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from lxml import etree\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from ctypes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PictureUrl:\n",
    "    def __init__(self, url_info, host_headers):\n",
    "        picture_url = url_info.split(';')[0]\n",
    "        self.title = url_info.split(';')[2]\n",
    "        self.start_number = url_info.split(';')[1].split('-')[0]\n",
    "        self.end_number = url_info.split(';')[1].split('-')[1]\n",
    "        self.save_path = \"d:/pictures/\"\n",
    "        self.urls = []\n",
    "        self.href = picture_url\n",
    "        self.is_found = True\n",
    "\n",
    "        self.host_headers = host_headers\n",
    "        self.item_number = re.findall('(\\d+)', self.href)[0]\n",
    "        file_path = self.save_path + re.sub('[\\/:*?\"<>|]', '', self.title.strip())\n",
    "        self.header_url = 'https://mtl.gzhuibei.com/images/img/'\n",
    "        if not os.path.exists(file_path):\n",
    "            os.makedirs(file_path)\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def get_image_url(self):\n",
    "        if self.is_found:\n",
    "            for j in range(int(self.start_number), int(self.end_number) + 1):\n",
    "                url = self.header_url + str(self.item_number) + r'/' + str(j) + '.jpg'\n",
    "                self.urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrawlerPictures:\n",
    "    def __init__(self, urls_file):\n",
    "        self.urls_file = urls_file\n",
    "        self.max_page_number = 1\n",
    "        self.first_layer_urls = []\n",
    "        self.picture_urls = []\n",
    "        self.host_headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36',\n",
    "        }\n",
    "\n",
    "        self.picture_headers = {\n",
    "            'Host': 'mtl.gzhuibei.com',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/s',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "            'Cache-Control': 'max-age=0',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Sec-Fetch-Dest': 'document',\n",
    "            'Sec-Fetch-Mode': 'navigate',\n",
    "            'Sec-Fetch-Site': 'none',\n",
    "            'Sec-Fetch-User': '?1',\n",
    "            'Content-Type': 'text/html; charset=UTF-8',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36'\n",
    "        }\n",
    "\n",
    "    # 获取第一层所有url\n",
    "    def get_first_layer_url(self):\n",
    "        with open(self.urls_file, 'r', encoding='UTF-8') as file_lines:\n",
    "            lines = file_lines.readlines()\n",
    "            for line in lines:\n",
    "                picture = PictureUrl(line, self.host_headers)\n",
    "                picture.get_image_url()\n",
    "                self.first_layer_urls.append(picture)\n",
    "\n",
    "    # 获取所有图片\n",
    "    def get_images(self):\n",
    "        print(\"start get images\")\n",
    "        for picture in self.first_layer_urls:\n",
    "            print(\"start get \" + picture.title)\n",
    "            for url in picture.urls:\n",
    "                self.get_image(url, picture.file_path)\n",
    "                \n",
    "    def get_image(self, url, file_path):\n",
    "        file_name = file_path + '/' + url.split(r'/')[-1]\n",
    "        image_html = requests.get(url, headers=self.picture_headers)\n",
    "        with open(file_name, 'wb') as file_obj:\n",
    "            file_obj.write(image_html.content)\n",
    "        #time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start get images\n",
      "start get [XIUREN秀人网] No.1821 模特@Angela小热巴 - 故事情节秘书装系列\n",
      "\n",
      "start get [XIUREN秀人网] No.1808 女神@Angela小热巴 - 性感黑丝写真\n",
      "\n",
      "start get [XIAOYU语画界] Vol.244 Angela小热巴 ~ 内衣私房写真\n",
      "\n",
      "start get [XIAOYU语画界] Vol.236 Angela小热巴 - 古典韵味旗袍与魅惑丝袜装扮\n",
      "\n",
      "start get [XIAOYU语画界] Vol.229 Angela小热巴  - 皮裤的飒爽，丝袜的朦胧\n",
      "\n",
      "start get [XIAOYU语画界] Vol.223 Angela小热巴 - 浴池之内的诱人酥胸与芊芊美腿\n",
      "\n",
      "start get [XIAOYU语画界] Vol.211 Angela小热巴 - 有浴室衬衫湿身系列\n",
      "\n",
      "start get [XIAOYU语画界] VOL.198 性感女神@Angela小热巴魅惑写真\n",
      "\n",
      "start get [UGIRLS尤果圈] No.1732 栗子&小琪 - 双倍恋爱 写真套图\n",
      "\n",
      "start get [UGIRLS尤果圈] No.1731 小琪&栗子 - 情节特殊 写真套图\n",
      "\n",
      "start get [HuaYang花漾] Vol.188 女神@奶瓶土肥圆矮挫丑黑穷 - 富国岛旅拍\n",
      "\n",
      "start get [XIUREN秀人网] No.1816 性感女神@奶瓶土肥圆矮挫丑黑穷魅惑私房写真\n",
      "\n",
      "start get [XIUREN秀人网] No.1830 就是阿朱啊 - 户外草地主题\n"
     ]
    }
   ],
   "source": [
    "crawler_picture = CrawlerPictures('urls.txt')\n",
    "crawler_picture.get_first_layer_url()\n",
    "crawler_picture.get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://mtl.gzhuibei.com/images/img/20828/49.jpg\"\n",
    "host_headers = {\n",
    "    'Host': 'mtl.gzhuibei.com',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/s',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'none',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Content-Type': 'text/html; charset=UTF-8',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36',\n",
    "        }\n",
    "\n",
    "html = requests.get(url, headers=host_headers)\n",
    "file_name = r'D:\\pictures\\1.jpg'\n",
    "with open(file_name, 'wb') as file_obj:\n",
    "    file_obj.write(html.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
